{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a FloPy model of the basin\n",
    "\n",
    "Let's start with importing the functionality needed in this notebook:\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as pl\n",
    "\n",
    "# FloPy\n",
    "import flopy\n",
    "from flopy.discretization import VertexGrid\n",
    "from flopy.utils.triangle import Triangle\n",
    "from flopy.utils.voronoi import VoronoiGrid\n",
    "\n",
    "# Local convenience\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Voronoi Grid\n",
    "\n",
    "Start with setting the refinement parameters for the grid. (Decreasing these numbers will generate a discretization that is more refined, i.e. has more nodes, and is therefore expected to have a better parallel efficiency.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is a scale parameter: a larger number will\n",
    "# lead to more nodes in the simulation\n",
    "scale = 1.0\n",
    "\n",
    "# don't put in too large on a number (or get rid of this check)\n",
    "if scale > 10.0:\n",
    "  raise ValueError(f\"This will generate more than 5M cells, are you sure?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the boundary refinement parameter is converted to a maximum area\n",
    "# that is input to the triangulation below\n",
    "boundary_refinement = 1000.0 / scale\n",
    "max_boundary_area = boundary_refinement * boundary_refinement\n",
    "\n",
    "# the length scale for the distance between the\n",
    "# points of stream segments\n",
    "river_refinement = 500.0 / scale\n",
    "\n",
    "Lx*Ly/(river_refinement**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the boundary and stream segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the string with boundary points from defaults.py\n",
    "# and convert to an array\n",
    "boundary_vertices = string2geom(geometry[\"boundary\"])\n",
    "bp = np.array(boundary_vertices)\n",
    "\n",
    "# similar for all 4 stream segments\n",
    "stream_segs = (\n",
    "    geometry[\"streamseg1\"],\n",
    "    geometry[\"streamseg2\"],\n",
    "    geometry[\"streamseg3\"],\n",
    "    geometry[\"streamseg4\"],\n",
    ")\n",
    "sgs = [string2geom(sg) for sg in stream_segs]\n",
    "\n",
    "# prepare figure\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# force equal x and y scales\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# plot boundary points\n",
    "ax.plot(bp[:, 0], bp[:, 1], \"ro-\")\n",
    "\n",
    "# loop over stream segments and plot\n",
    "riv_colors = (\"blue\", \"cyan\", \"green\", \"orange\")\n",
    "for idx, sg in enumerate(sgs):\n",
    "    sa = np.array(sg)\n",
    "    ax.plot(\n",
    "        sa[:, 0],\n",
    "        sa[:, 1],\n",
    "        color=riv_colors[idx],\n",
    "        lw=0.75,\n",
    "        marker=\"o\",\n",
    "        mfc=\"none\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more points to river network for triangulation\n",
    "\n",
    "With the refinement scale defined above, the stream geometries are now refined by adding additional points to their line segments. This will be input to the Triangle program in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add extra nodes\n",
    "triangle_nodes = []\n",
    "for sg in sgs:\n",
    "    triangle_nodes.extend(densify_geometry(sg, river_refinement))\n",
    "triangle_nodes = np.array(triangle_nodes)\n",
    "\n",
    "# plot stream network\n",
    "fig = plt.figure(figsize=(6,2))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.plot(triangle_nodes[:, 0], triangle_nodes[:, 1], \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Triangle to create the mesh\n",
    "\n",
    "We use the FloPy Triangle class here, which is based on the two-dimensional mesh generator and Delaunay triangulator called Triangle. More information on the triangle program can be found at https://www.cs.cmu.edu/~quake/triangle.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a workspace directory for the program\n",
    "triangle_ws = pl.Path(\"temp/triangle\")\n",
    "triangle_ws.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create and run Triangle, using the maximum cell area configured earlier, the refined nodes from the stream segments, and the boundary polygon to constrain the extend of the generated grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Triangle with the streams\n",
    "tri = Triangle(\n",
    "    angle=30,\n",
    "    maximum_area=max_boundary_area,\n",
    "    nodes=triangle_nodes,\n",
    "    model_ws=triangle_ws,\n",
    ")\n",
    "\n",
    "# add the boundary\n",
    "tri.add_polygon(bp)\n",
    "\n",
    "# generate the triangular mesh (the intermediate results should be in the model_ws directory)\n",
    "tri.build(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Voronoi and create the VertexGrid object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Voronoi\n",
    "vor = VoronoiGrid(tri)\n",
    "\n",
    "# create the working grid (which only has a single layer)\n",
    "gridprops = vor.get_gridprops_vertexgrid()\n",
    "idomain = np.ones((1, vor.ncpl), dtype=int)\n",
    "working_grid = VertexGrid(\n",
    "    **gridprops,\n",
    "    nlay=1,\n",
    "    idomain=idomain,\n",
    "    top=np.full((vor.ncpl), 1000.0),\n",
    "    botm=np.full((1, vor.ncpl), -100.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the raw topography\n",
    "\n",
    "Load a raster file with elevation data into a FloPy Raster object and resample the data to the working grid created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the elevation data into a Raster object\n",
    "fine_topo = flopy.utils.Raster.load(\"./grid_data/fine_topo.asc\")\n",
    "\n",
    "# resample to the (single-layer) working grid\n",
    "top_wg = fine_topo.resample_to_grid(\n",
    "    working_grid,\n",
    "    band=fine_topo.bands[0],\n",
    "    method=\"linear\",\n",
    "    extrapolate_edges=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect river segments with grid\n",
    "\n",
    "Here we use a helper function to intersect the river segments with the working grid. The figure shows where they lie by coloring the intersected cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersect with working grid\n",
    "ixs, cellids, lengths = intersect_segments(working_grid, sgs)\n",
    "\n",
    "# generate a mask array (==1) where river intersects grid cells\n",
    "intersection_rg = np.zeros(working_grid.shape[1:])\n",
    "for loc in cellids:\n",
    "    intersection_rg[loc] = 1\n",
    "\n",
    "# prepare figure\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot()\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=working_grid)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# add topography to plot\n",
    "pmv.plot_array(top_wg)\n",
    "\n",
    "# plot river-grid intersection\n",
    "pmv.plot_array(\n",
    "    intersection_rg,\n",
    "    masked_values=[\n",
    "        0,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create top and bottom coordinates for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of layers for the simulatio\n",
    "nlay = 5\n",
    "\n",
    "# this parameter sets the thickness of layer 1\n",
    "dv0 = 5.0\n",
    "\n",
    "# Note: top array not used?\n",
    "topc = np.zeros((nlay, vor.ncpl), dtype=float)\n",
    "botm = np.zeros((nlay, vor.ncpl), dtype=float)\n",
    "dv = dv0\n",
    "topc[0] = top_wg.copy()\n",
    "botm[0] = topc[0] - dv\n",
    "for idx in range(1, nlay):\n",
    "    dv *= 1.5\n",
    "    topc[idx] = botm[idx - 1]\n",
    "    botm[idx] = topc[idx] - dv\n",
    "\n",
    "# Check: print cell thickness:\n",
    "for k in range(nlay):\n",
    "    print(f\"thickness layer {k+1} =\", (topc[k] - botm[k]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create drain data for river segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakance = 1.0 / (0.5 * dv0)  # kv / b\n",
    "\n",
    "# call helper function to build drain package data for stream segments\n",
    "drn_data = build_drain_data(\n",
    "    working_grid,\n",
    "    cellids,\n",
    "    lengths,\n",
    "    leakance,\n",
    "    top_wg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set starting head equal to the top of the model grid\n",
    "strt = np.array([top_wg.copy() for k in range(nlay)], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check: size of the model\n",
    "\n",
    "For the parallel solution of an iterative system, the number of degrees of freedom in the problem has a big influence on efficiency when scaling up to a larger number of processors. A guiding principle (also coming from the PETSc development team) is that when splitting the simulation into multiple models, the size of each of these domains should not be smaller than 20-30k grid cells for the parallel solver to work efficiently. When the domains get too small, much of the simulation run time is spent on communication instead of computation. Note that to prepare for parallel runs later on the exercise, you can tune the `scale` parameter above to increase the number of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the minimum number of cells per domain\n",
    "min_dof_domain = 25000\n",
    "\n",
    "# nr. of active cells\n",
    "nr_active_cells = strt.size\n",
    "print(f\"Nr. active cells = {nr_active_cells:,}\")\n",
    "\n",
    "# maximum nr. of domains\n",
    "max_nr_domains = max(int(nr_active_cells/min_dof_domain), 1)\n",
    "print(f\"Max. nr of domains = {max_nr_domains}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If you are happy with the numbers printed here, proceed and write the simulation to disk. Otherwise, go back and modify the `scale` parameter. A good practice is to first continue the workflow with a relatively small model to ensure that everything is working properly. Then, when analyzing performance, start increasing the scale of the problem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the FloPy simulation and write to disk\n",
    "\n",
    "All required pre-processing has been done. Here we build the FloPy simulation object, with the groundwater flow model and its packages. First clean any existing folders with model data, if any. (This will delete previously generated simulations as they are most likely invalid because the base model has been changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = get_workspace_dir()\n",
    "if base_folder.exists():\n",
    "  shutil.rmtree(base_folder, ignore_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the workspace folder for this baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ws = get_serial_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now construct the simulation object using all the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simulation object set to its workspace directory\n",
    "sim = flopy.mf6.MFSimulation(\n",
    "    sim_ws=sim_ws,\n",
    "    exe_name=\"mf6\",\n",
    ")\n",
    "\n",
    "# time discretization\n",
    "tdis = flopy.mf6.ModflowTdis(sim)\n",
    "\n",
    "# linear solver settings\n",
    "ims = flopy.mf6.ModflowIms(\n",
    "    sim,\n",
    "    complexity=\"simple\",\n",
    "    print_option=\"SUMMARY\",\n",
    "    linear_acceleration=\"bicgstab\",\n",
    "    outer_maximum=1000,\n",
    "    inner_maximum=100,\n",
    "    outer_dvclose=1e-5,\n",
    "    inner_dvclose=1e-6,\n",
    "    preconditioner_levels=2,\n",
    "    relaxation_factor=0.0,\n",
    ")\n",
    "\n",
    "# the groundwater flow model\n",
    "gwf = flopy.mf6.ModflowGwf(\n",
    "    sim,\n",
    "    save_flows=True,\n",
    "    print_input=True,\n",
    "    newtonoptions=\"NEWTON UNDER_RELAXATION\",\n",
    ")\n",
    "\n",
    "# its spatial discretization: DISV\n",
    "dis = flopy.mf6.ModflowGwfdisv(\n",
    "    gwf,\n",
    "    nlay=nlay,\n",
    "    ncpl=vor.ncpl,\n",
    "    nvert=vor.nverts,\n",
    "    vertices=vor.get_disv_gridprops()[\"vertices\"],\n",
    "    cell2d=vor.get_disv_gridprops()[\"cell2d\"],\n",
    "    top=top_wg,\n",
    "    botm=botm,\n",
    "    xorigin=0.0,\n",
    "    yorigin=0.0,\n",
    ")\n",
    "\n",
    "# the initial conditions\n",
    "ic = flopy.mf6.ModflowGwfic(gwf, strt=strt)\n",
    "\n",
    "# the node property flow package \n",
    "# (constant hydraulic conductivity, unconfined)\n",
    "npf = flopy.mf6.ModflowGwfnpf(\n",
    "    gwf,\n",
    "    save_specific_discharge=True,\n",
    "    icelltype=1,\n",
    "    k=1.0,\n",
    ")\n",
    "\n",
    "# constant recharche on the entire domain\n",
    "rch = flopy.mf6.ModflowGwfrcha(\n",
    "    gwf,\n",
    "    recharge=0.000001,\n",
    ")\n",
    "\n",
    "# drain package for the rivers\n",
    "drn = flopy.mf6.ModflowGwfdrn(\n",
    "    gwf,\n",
    "    stress_period_data=drn_data,\n",
    "    pname=\"river\",\n",
    "    filename=\"drn_riv.drn\",\n",
    ")\n",
    "\n",
    "# output control\n",
    "oc = flopy.mf6.ModflowGwfoc(\n",
    "    gwf,\n",
    "    head_filerecord=f\"{gwf.name}.hds\",\n",
    "    budget_filerecord=f\"{gwf.name}.cbc\",\n",
    "    saverecord=[(\"HEAD\", \"ALL\"), (\"BUDGET\", \"ALL\")],\n",
    "    printrecord=[(\"BUDGET\", \"ALL\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to write the simulation input files to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this if the 'mf6' program is not in your path\n",
    "sim.exe_name = 'mf6'\n",
    "\n",
    "# run\n",
    "sim.run_simulation(processors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when running the simulation the argument `processors=1` is passed. This forces the parallel PETSc solver to be used, even when running on a single processor. This way the comparison between this baseline result and the parallel, multi-model simulations will not include the difference in performance between the serial MODFLOW IMS solver and the PETSc linear solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
